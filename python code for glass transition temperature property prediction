import pandas as pd
import numpy as np
from rdkit import Chem
from rdkit.Chem import AllChem
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor, AdaBoostRegressor
from catboost import CatBoostRegressor

# Load the dataset
data = pd.read_csv('enhanced_polymer_data.csv')

# Function to compute ECFP4 fingerprints
def compute_ecfp4(smiles):
    if pd.notnull(smiles):
        mol = Chem.MolFromSmiles(smiles)  # Convert SMILES to RDKit molecule object
        if mol is not None:
            return AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)  # Generate ECFP4 fingerprint
    return None

# Apply the fingerprint computation to the SMILES column
data['ECFP4'] = data['SMILES'].apply(compute_ecfp4)

# Convert the ECFP4 fingerprints from RDKit BitVector to a binary array
def ecfp_to_array(ecfp):
    if ecfp is not None:
        return np.array(ecfp)  # Convert BitVector to numpy array
    return np.zeros(1024)  # Return a zero array if the fingerprint is None

data['ECFP4'] = data['ECFP4'].apply(ecfp_to_array)

# Create a DataFrame for the ECFP4 fingerprints and merge it with the original data
ecfp_df = pd.DataFrame(data['ECFP4'].to_list(), index=data.index, columns=[f'ecfp_{i}' for i in range(1024)])
data = pd.concat([data.drop(columns=['ECFP4', 'SMILES']), ecfp_df], axis=1)

# Handle missing values
data.replace([np.inf, -np.inf], np.nan, inplace=True)
data.fillna(data.median(), inplace=True)

# Prepare features and target variable
X = data.drop(columns=['Tg (K)'])
y = data['Tg (K)']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Impute missing values and scale features
imputer = SimpleImputer(strategy='median')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_imputed)
X_test_scaled = scaler.transform(X_test_imputed)

# Define regression models for evaluation
models = {
    "LGBMRegressor": LGBMRegressor(random_state=42),
    "ExtraTreesRegressor": ExtraTreesRegressor(random_state=42),
    "XGBRegressor": XGBRegressor(random_state=42),
    "DecisionTreeRegressor": DecisionTreeRegressor(random_state=42),
    "SVR": SVR(),
    "KNeighborsRegressor": KNeighborsRegressor(),
    "RandomForestRegressor": RandomForestRegressor(random_state=42),
    "HistGradientBoostingRegressor": HistGradientBoostingRegressor(random_state=42),
    "AdaBoostRegressor": AdaBoostRegressor(random_state=42),
    "CatBoostRegressor": CatBoostRegressor(random_state=42, verbose=0),
}

# Function to evaluate model performance
def evaluate_model(model, X_train, X_test, y_train, y_test):
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
    
    print(f"Train RMSE: {train_rmse:.2f} | Test RMSE: {test_rmse:.2f}")

# Train and evaluate each model
for name, model in models.items():
    print(f"Training {name}...")
    model.fit(X_train_scaled, y_train)
    evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)
